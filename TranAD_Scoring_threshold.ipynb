{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상위 몇 %를 잘라서 이상치로 보았을 때, 그 안의 precision이 가장 높은 구간\n",
    "def find_best_percent(result, granularity_all=1000):\n",
    "    \"\"\"\n",
    "    find threshold\n",
    "    :param result: sorted result\n",
    "    :param granularity_all: granularity_all\n",
    "    \"\"\"\n",
    "    max_percent = 0\n",
    "    best_n = 1\n",
    "    print(\"threshold tuning start:\")\n",
    "    for n in tqdm(range(1, 100)):\n",
    "        head_n = n / granularity_all\n",
    "        data_length = max(round(len(result) * head_n), 1)\n",
    "        count_dist = count_entries(result.loc[:data_length - 1], 'label')\n",
    "        try:\n",
    "            percent = count_dist['1'] / max(1,(count_dist['0'] + count_dist['1']))\n",
    "            # anormal 갯수 파악.\n",
    "        except KeyError:\n",
    "            print(\"can't find n%,take 1%\")\n",
    "            percent = 0.01\n",
    "        if percent > max_percent:\n",
    "            max_percent = percent\n",
    "            best_n = n\n",
    "    print(\"top %d / %s is the highest, %s\" % (granularity_all, best_n, max_percent))\n",
    "    print(\"Count dist : \" ,count_dist)\n",
    "    return best_n, max_percent, granularity_all\n",
    "\n",
    "def count_entries(df, col_name):\n",
    "    \"\"\"\n",
    "    count\n",
    "    \"\"\"\n",
    "    count_dist = {'0': 0, '1': 0}\n",
    "    col = df[col_name]\n",
    "    for entry in col:\n",
    "        if str(int(entry)) in count_dist.keys():\n",
    "            count_dist[str(int(entry))] = count_dist[str(int(entry))] + 1\n",
    "        else:\n",
    "            count_dist[str(int(entry))] = 1\n",
    "    return count_dist\n",
    "\n",
    "def find_best_result(threshold_n, result, dataframe_std):\n",
    "    \"\"\"\n",
    "    find_best_result\n",
    "    :param threshold_n: threshold\n",
    "    :param result: sorted result\n",
    "    :param dataframe_std: label\n",
    "    \"\"\"\n",
    "    best_result, best_h, best_re, best_fa, best_f1, best_precision = None, 0, 0, 0, 0, 0\n",
    "    best_auroc = 0\n",
    "    for h in tqdm(range(10, 1000, 5)):\n",
    "        train_result = charge_to_car(threshold_n, result, head_n=h)\n",
    "        f1, recall, false_rate, precision, accuracy, auroc = evaluation(dataframe_std, train_result)\n",
    "        if auroc >= best_auroc:\n",
    "            best_f1 = f1\n",
    "            best_h = h\n",
    "            best_re = recall\n",
    "            best_precision = precision\n",
    "            best_result = train_result\n",
    "            best_auroc = auroc\n",
    "    return best_result, best_h, best_re, best_precision, best_f1, best_auroc\n",
    "\n",
    "def charge_to_car(threshold_n, rec_result, head_n=92):\n",
    "    \"\"\"\n",
    "    mapping from charge to car\n",
    "    :param threshold_n: threshold\n",
    "    :param rec_result: sorted result\n",
    "    :param head_n: top %n\n",
    "    :param gran: granularity\n",
    "    \"\"\"\n",
    "    gran = 1000\n",
    "    result = []\n",
    "    for grp in rec_result.groupby('car'):\n",
    "        temp = grp[1].values[:, -1].astype(float)\n",
    "        idx = max(round(head_n / gran * len(temp)), 1)\n",
    "        error = np.mean(temp[:idx])  \n",
    "        result.append([grp[0], int(error > threshold_n), error, threshold_n])\n",
    "\n",
    "        \"\"\" top_errors = temp[:idx]\n",
    "        snip_pred = (top_errors > threshold_n).astype(int)\n",
    "\n",
    "        ratio = snip_pred.mean() # head_n %의 구간 중 이상 스니펫 비율\n",
    "        # result.append([grp[0], int(ratio > 0), error, threshold_n]) \"\"\" \n",
    "    return pd.DataFrame(result, columns=['car', 'predict', 'error', 'threshold_n'])\n",
    "\n",
    "def evaluation(dataframe_std, dataframe):\n",
    "    \"\"\"\n",
    "    calculated statistics\n",
    "    :param dataframe_std:\n",
    "    :param dataframe:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate auroc\n",
    "#     print(dataframe) # error car\n",
    "    _label = []\n",
    "    for each_car in dataframe['car']:\n",
    "        if int(each_car) in ind_car_num_list:\n",
    "            _label.append(0)\n",
    "        if int(each_car) in ood_car_num_list:\n",
    "            _label.append(1)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(_label, list(dataframe['error']), pos_label=1)\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    data = pd.merge(dataframe_std, dataframe, on='car')\n",
    "    cm = confusion_matrix(data['label'].astype(int), data['predict'].astype(int))\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    tp = cm[1, 1] \n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "    false_rate = fp / (tn + fp) if tn + fp != 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if tp + tn + fp + fn != 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else 0\n",
    "    return f1, recall, false_rate, precision, accuracy, auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013cb1ad",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = [\"1\",\"2\",\"3\"]\n",
    "brand_num = 0\n",
    "\n",
    "train_label_obj = np.load(f\"./AUROCscore/labels/brand3/train_labels.npy\",allow_pickle=True).item()\n",
    "test_label_obj = np.load(f\"./AUROCscore/labels/brand3/labels.npy\",allow_pickle=True).item()\n",
    "train_scores = np.load(f\"./AUROCscore/scores/brand3/tranad_1_epochs5_lr1e-3/train_scores.npy\",allow_pickle=True).item()\n",
    "test_scores = np.load(f\"./AUROCscore/scores/brand3/tranad_1_epochs5_lr1e-3/test_scores.npy\",allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[372, 86, 367, 463, 646, 531, 310, 717, 196, 542, 488, 340, 733, 1236, 1034, 147, 265, 236, 222, 111, 49, 357, 738, 308, 531, 81, 142, 302, 438, 349, 160, 730, 127, 163, 171, 260, 91, 267, 95, 143, 123, 277, 221, 325, 80, 227, 601, 109, 114, 104, 289, 370, 108, 167, 200, 453, 100, 268, 160, 318, 589, 319, 260, 95, 138, 56, 164, 46, 24, 29, 53, 78, 12]\n",
      "[208, 126, 103, 170, 304, 138, 425, 167, 82, 860, 91, 355, 864, 980, 250, 270, 202, 159, 509, 266, 208, 57, 137, 129, 937, 503, 77]\n",
      "{203: 0, 204: 1, 205: 1, 206: 1, 209: 1, 210: 1, 212: 1, 213: 0, 215: 1, 217: 0, 219: 1, 225: 1, 226: 0, 235: 0, 236: 1, 237: 1, 239: 1, 240: 1, 241: 1, 243: 1, 247: 1, 249: 0}\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "for k,v in train_scores.items():\n",
    "    train_list.append(len(v))\n",
    "print(train_list)\n",
    "\n",
    "test_list = []\n",
    "for k,v in test_scores.items():\n",
    "    test_list.append(len(v))\n",
    "print(test_list)\n",
    "print(test_label_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea15cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' train_temp = train_scores.copy()\\ntest_temp = test_scores.copy()\\nfor cid, data in train_scores.items():\\n    if len(data)<100 : \\n        del train_temp[cid]\\n        del train_label_obj[cid]\\n\\nfor cid, data in test_scores.items():\\n    if len(data) <100 :\\n        del test_temp[cid]\\n        del test_label_obj[cid]\\n\\nprint(len(train_temp.keys()))\\nprint(len(test_temp.keys()))\\n\\ntrain_scores = train_temp\\ntest_scores = test_temp '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" train_temp = train_scores.copy()\n",
    "test_temp = test_scores.copy()\n",
    "for cid, data in train_scores.items():\n",
    "    if len(data)<100 : \n",
    "        del train_temp[cid]\n",
    "        del train_label_obj[cid]\n",
    "\n",
    "for cid, data in test_scores.items():\n",
    "    if len(data) <100 :\n",
    "        del test_temp[cid]\n",
    "        del test_label_obj[cid]\n",
    "\n",
    "print(len(train_temp.keys()))\n",
    "print(len(test_temp.keys()))\n",
    "\n",
    "train_scores = train_temp\n",
    "test_scores = test_temp \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bedcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "train_scores.update(test_scores) # train, test 하나로 합침.\n",
    "ind_car_num_list = list(train_label_obj.keys())\n",
    "ood_car_num_list = []\n",
    "\n",
    "for k,v in test_label_obj.items():\n",
    "    if test_label_obj[k]==1:\n",
    "        ood_car_num_list.append(k)\n",
    "    else :\n",
    "        ind_car_num_list.append(k)\n",
    "\n",
    "all_car_num_list = set(ind_car_num_list + ood_car_num_list)\n",
    "print(len(all_car_num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for car_id, snippet_scores in train_scores.items():\n",
    "    if car_id in ind_car_num_list:\n",
    "        label = 0\n",
    "    elif car_id in ood_car_num_list:\n",
    "        label = 1\n",
    "    else :\n",
    "        continue\n",
    "\n",
    "    for s in snippet_scores:\n",
    "        rows.append([car_id,label,float(s)])\n",
    "\n",
    "all_snippet_df = pd.DataFrame(rows,columns=['car','label','rec_error'])\n",
    "print(len(ind_car_num_list))\n",
    "print(len(ood_car_num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for each_car in all_car_num_list:\n",
    "    if each_car in ind_car_num_list:\n",
    "        label = 0\n",
    "    elif each_car in ood_car_num_list:\n",
    "        label = 1\n",
    "    labels.append([each_car,int(label)])\n",
    "dataframe = pd.DataFrame(labels,columns=['car','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48951bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold tuning start:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 18651.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1000 / 1 is the highest, 0\n",
      "Count dist :  {'0': 0, '1': 0}\n",
      "threshold_n 1e-07\n",
      "start tuning, flag is rec_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/198 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "cannot do a non-empty take from an empty axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold_n\u001b[39m\u001b[38;5;124m\"\u001b[39m, threshold_n)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart tuning, flag is\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m best_result, best_h, best_re, best_fa, best_f1, best_auroc \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m best_result\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe_std is \u001b[39m\u001b[38;5;124m'\u001b[39m, dataframe\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&&   dataframe is \u001b[39m\u001b[38;5;124m'\u001b[39m, best_result\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[114], line 52\u001b[0m, in \u001b[0;36mfind_best_result\u001b[0;34m(threshold_n, result, dataframe_std)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m5\u001b[39m)):\n\u001b[1;32m     51\u001b[0m     train_result \u001b[38;5;241m=\u001b[39m charge_to_car(threshold_n, result, head_n\u001b[38;5;241m=\u001b[39mh)\n\u001b[0;32m---> 52\u001b[0m     f1, recall, false_rate, precision, accuracy, auroc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auroc \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m best_auroc:\n\u001b[1;32m     54\u001b[0m         best_f1 \u001b[38;5;241m=\u001b[39m f1\n",
      "Cell \u001b[0;32mIn[114], line 102\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(dataframe_std, dataframe)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(each_car) \u001b[38;5;129;01min\u001b[39;00m ood_car_num_list:\n\u001b[1;32m    100\u001b[0m         _label\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m auroc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n\u001b[1;32m    106\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(dataframe_std, dataframe, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tranad/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tranad/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1163\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1060\u001b[0m     {\n\u001b[1;32m   1061\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m ):\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1163\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tranad/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:901\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    898\u001b[0m threshold_idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[distinct_value_indices, y_true\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# accumulate the true positives with decreasing threshold\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m tps \u001b[38;5;241m=\u001b[39m \u001b[43mstable_cumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m[threshold_idxs]\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# express fps as a cumsum to ensure fps is increasing even in\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# the presence of floating point errors\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     fps \u001b[38;5;241m=\u001b[39m stable_cumsum((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m weight)[threshold_idxs]\n",
      "File \u001b[0;32m~/miniconda3/envs/tranad/lib/python3.10/site-packages/sklearn/utils/extmath.py:1238\u001b[0m, in \u001b[0;36mstable_cumsum\u001b[0;34m(arr, axis, rtol, atol)\u001b[0m\n\u001b[1;32m   1235\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1236\u001b[0m expected \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[0;32m-> 1238\u001b[0m     \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m, expected, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m ):\n\u001b[1;32m   1240\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1241\u001b[0m         (\n\u001b[1;32m   1242\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcumsum was found to be unstable: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m   1246\u001b[0m     )\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mIndexError\u001b[0m: cannot do a non-empty take from an empty axes."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, precision_recall_fscore_support\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "AUC_fivefold_list = []\n",
    "plt.figure(figsize=(9,6))\n",
    "for i in range(5):\n",
    "    \n",
    "    fold_num = i\n",
    "    test_car_list = ind_car_num_list[\n",
    "        int(fold_num * len(ind_car_num_list) / 5) : int((fold_num + 1) * len(ind_car_num_list) / 5)\n",
    "    ] + ood_car_num_list[: int(fold_num * len(ood_car_num_list) / 5)] \\\n",
    "      + ood_car_num_list[int((fold_num + 1) * len(ood_car_num_list) / 5) :]\n",
    "    test_car_list = set(test_car_list)\n",
    "    train_car_list = all_car_num_list - test_car_list\n",
    "\n",
    "    print(f\"Fold Num{fold_num} Test car List : {test_car_list}\")\n",
    "    print(f\"Fold Num{fold_num} Train car List : {train_car_list}\")\n",
    "    # ------------------------------\n",
    "    # Train part: threshold_n, best_h 튜닝\n",
    "    # ------------------------------\n",
    "    train_result = all_snippet_df[all_snippet_df['car'].isin(train_car_list)].copy()\n",
    "    test_result  = all_snippet_df[all_snippet_df['car'].isin(test_car_list)].copy()      \n",
    "    \n",
    "    train_res_csv = train_result[['label','car','rec_error']].to_numpy()\n",
    "    test_res_csv  = test_result[['label','car','rec_error']].to_numpy()\n",
    "\n",
    "    rec_sorted_index = np.argsort(-train_res_csv[:, 2].astype(float))  # 정렬한 인덱스 반환\n",
    "    res = [train_res_csv[j][[1, 0, 2]] for j in rec_sorted_index]      # [car, label, rec_error]\n",
    "    result = pd.DataFrame(res, columns=['car', 'label', 'rec_error'])\n",
    "    \n",
    "    best_n, max_percent, granularity = find_best_percent(result, granularity_all=1000)\n",
    "    head_n = best_n / granularity\n",
    "    data_length = 1,round(len(result) * head_n)\n",
    "    # threshold_n : precision이 최대가 되는 지점의 임계값.\n",
    "    if result.empty:\n",
    "        threshold_n = 1e-7\n",
    "    else : \n",
    "        threshold_n = result['rec_error'].values[data_length - 1].astype(float)\n",
    "    \n",
    "    print(\"threshold_n\", threshold_n)\n",
    "    print(\"start tuning, flag is\", 'rec_error')\n",
    "    best_result, best_h, best_re, best_fa, best_f1, best_auroc = find_best_result(\n",
    "        threshold_n, result, dataframe\n",
    "    )\n",
    "    if dataframe.shape[0] != best_result.shape[0]:\n",
    "        print('dataframe_std is ', dataframe.shape[0], '&&   dataframe is ', best_result.shape[0])\n",
    "        \n",
    "    print(\"F1 Scores through Train data\")\n",
    "    print(\"best 1000 / %d:\" % best_h)\n",
    "    print(\"re:\", best_re)\n",
    "    print(\"fa:\", best_fa)\n",
    "    print(\"F1:\", best_f1)\n",
    "    \n",
    "    # ------------------------------\n",
    "    # Test part: charge_to_car → car-level score / 예측\n",
    "    # ------------------------------\n",
    "    rec_sorted_index = np.argsort(-test_res_csv[:, 2].astype(float))\n",
    "    res = [test_res_csv[j][[1, 0, 2]] for j in rec_sorted_index]\n",
    "    result = pd.DataFrame(res, columns=['car', 'label', 'rec_error'])\n",
    "    result['car'] = result['car'].astype(\"int\").astype(\"str\")\n",
    "\n",
    "    test_result_car = charge_to_car(threshold_n, result, head_n=best_h)\n",
    "    # columns: ['car', 'predict', 'error', 'threshold_n']\n",
    "\n",
    "    _score = list(test_result_car['error'])\n",
    "    y_true = []\n",
    "    for each_car in test_result_car['car']:\n",
    "        if int(each_car) in ind_car_num_list:\n",
    "            y_true.append(0)\n",
    "        if int(each_car) in ood_car_num_list:\n",
    "            y_true.append(1)\n",
    "    y_pred = list(test_result_car['predict'])  # charge_to_car에서 0/1로 만들어 둔 것\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, pos_label=1, average='binary'\n",
    "    )\n",
    "\n",
    "    print(\"F1 Score through Test data\")\n",
    "    print(\"Test Precision:\", precision)\n",
    "    print(\"Test Recall:\", recall)\n",
    "    print(\"Test F1:\", f1)\n",
    "\n",
    "    print('len(_score)', len(_score))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, _score, pos_label=1)\n",
    "    auc_fold = auc(fpr, tpr)\n",
    "    print('AUC', auc_fold)\n",
    "    # np.save(f\"/results/true_score_fold{i}.npy\",y_true)\n",
    "    # np.save(f\"/results/pred_score_fold{i}.npy\",_score)\n",
    "    # fold별 ROC 그리기\n",
    "    plt.plot(fpr, tpr, alpha=0.3, label=f\"Fold {i} AUC = {auc_fold:.3f}\")\n",
    "\n",
    "    # mean ROC 계산용 보간\n",
    "    tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "    tpr_interp[0] = 0.0\n",
    "    tprs.append(tpr_interp)\n",
    "    AUC_fivefold_list.append(auc_fold)\n",
    "\n",
    "# ------------------------------\n",
    "# 5-fold 평균 ROC + 표준편차 밴드\n",
    "# ------------------------------\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "std_tpr  = np.std(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0  # 끝점 보정\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"blue\",\n",
    "    lw=2,\n",
    "    label=f\"Mean ROC (AUC={np.mean(AUC_fivefold_list):.3f})\"\n",
    ")\n",
    "plt.fill_between(\n",
    "    mean_fpr,\n",
    "    mean_tpr - std_tpr,\n",
    "    mean_tpr + std_tpr,\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    "    label=\"± 1 std\"\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"Brand{brand[brand_num]} ROC with Mean ± Std (5-Fold, charge_to_car)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Fold AUCs:\", AUC_fivefold_list)\n",
    "print(\"AUC mean \", np.mean(AUC_fivefold_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b4cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tranad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
